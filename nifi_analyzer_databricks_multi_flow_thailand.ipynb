{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6791bf8-1576-4719-aaac-8ffd4cbd4d87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# NiFi Processor Usage Analyzer - Multi-Flow Edition\n",
    "\n",
    "This notebook analyzes NiFi processor execution counts across **multiple process groups** to identify unused or underutilized processors.\n",
    "\n",
    "**Features:**\n",
    "- Analyzes multiple flows from CSV input\n",
    "- Fast execution count analysis (~5-10 seconds per flow)\n",
    "- Snapshot mode with flow_name tracking\n",
    "- Delta Lake integration with timestamp\n",
    "- Standalone - no external files needed\n",
    "\n",
    "**Setup:**\n",
    "1. Upload CSV with flow definitions (id, flow_name)\n",
    "2. Edit the configuration in Cell 3\n",
    "3. Run all cells\n",
    "4. View results in Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adef03ec-294c-45f1-b52b-9b4bc98c7479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:25,528 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:26,529 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n✓ Dependencies installed successfully!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:27,542 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "%pip install requests rich --quiet\n",
    "print(\"✓ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea522c1a-91a6-46cf-b8c5-9958a4d56be0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Libraries\n",
    "\n",
    "import requests\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Any\n",
    "from datetime import datetime\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn\n",
    "\n",
    "# Databricks-specific imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, TimestampType\n",
    "\n",
    "# Disable SSL warnings\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('nifi_analyzer')\n",
    "\n",
    "# Initialize Rich console\n",
    "console = Console()\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2a83ba3-6c06-4fcc-9509-d19304cd414e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✓ Configuration loaded!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✓ Configuration loaded!\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  NiFi URL: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://thbnk01hdpnp002.th-bnk01.nxp.com:8443/nifi</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  NiFi URL: \u001b[4;94mhttps://thbnk01hdpnp002.th-bnk01.nxp.com:8443/nifi\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Username: nxg16670\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Username: nxg16670\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Server: thailand\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Server: thailand\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Flows CSV: <span style=\"color: #800080; text-decoration-color: #800080\">/Volumes/1dp_mfg_sbx/validation_test_eric/files/nifi_flow_status/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">nifi_group_ids_thailand.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Flows CSV: \u001b[35m/Volumes/1dp_mfg_sbx/validation_test_eric/files/nifi_flow_status/\u001b[0m\u001b[95mnifi_group_ids_thailand.csv\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Delta table: 1dp_mfg_sbx.validation_test_eric.nifi_processor_snapshots_full_attributes\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Delta table: 1dp_mfg_sbx.validation_test_eric.nifi_processor_snapshots_full_attributes\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Snapshots enabled: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Snapshots enabled: \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Cell 3: Configuration\n",
    "# EDIT THESE VALUES FOR YOUR NIFI INSTANCE\n",
    "\n",
    "CONFIG = {\n",
    "    # NiFi Connection\n",
    "    'nifi_url': 'https://thbnk01hdpnp002.th-bnk01.nxp.com:8443/nifi',\n",
    "    'username': 'nxg16670',\n",
    "    'password': '6be!x!_Ex855cXJ',  # ← EDIT THIS\n",
    "    'verify_ssl': False,\n",
    "    \n",
    "    # Server Identifier (for tracking multiple NiFi servers)\n",
    "    'server': 'thailand',  # ← EDIT THIS (e.g., 'prod', 'dev', hostname)\n",
    "    \n",
    "    # Flow Definitions CSV\n",
    "    # CSV Format: id,flow_name\n",
    "    # Example:\n",
    "    #   8c8677c4-29d6-36...,Production_Flow_1\n",
    "    #   abc-123-def...,Development_Flow_2\n",
    "    'flows_csv_path': '/Volumes/1dp_mfg_sbx/validation_test_eric/files/nifi_flow_status/nifi_group_ids_thailand.csv',  # ← Path to your CSV\n",
    "    \n",
    "    # Snapshot Storage (Unity Catalog - 3-level naming)\n",
    "    'enable_snapshots': True,\n",
    "    'delta_table_path': '1dp_mfg_sbx.validation_test_eric.nifi_processor_snapshots_full_attributes',  # catalog.schema.table\n",
    "}\n",
    "\n",
    "console.print(\"[green]✓ Configuration loaded![/green]\")\n",
    "console.print(f\"  NiFi URL: {CONFIG['nifi_url']}\")\n",
    "console.print(f\"  Username: {CONFIG['username']}\")\n",
    "console.print(f\"  Server: {CONFIG['server']}\")\n",
    "console.print(f\"  Flows CSV: {CONFIG['flows_csv_path']}\")\n",
    "console.print(f\"  Delta table: {CONFIG['delta_table_path']}\")\n",
    "console.print(f\"  Snapshots enabled: {CONFIG['enable_snapshots']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7358fe55-8364-4397-b48d-b6f9ef4327bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# Cell 4: NiFi Client Class - SIMPLIFIED PROCESSOR-LEVEL\n\nclass NiFiClient:\n    \"\"\"Client for interacting with Apache NiFi REST API.\"\"\"\n    \n    def __init__(self, base_url: str, username: str, password: str, verify_ssl: bool = True):\n        self.base_url = base_url.rstrip('/')\n        if not self.base_url.endswith('/nifi'):\n            self.base_url += '/nifi'\n        self.api_url = f\"{self.base_url}-api\"\n        self.verify_ssl = verify_ssl\n        self.session = requests.Session()\n        self.token = None\n        self.username = username\n        self.password = password\n        self._authenticate(username, password)\n        \n    def _authenticate(self, username: str, password: str) -> None:\n        \"\"\"Authenticate with NiFi.\"\"\"\n        try:\n            response = requests.post(\n                f\"{self.api_url}/access/token\",\n                data={'username': username, 'password': password},\n                verify=self.verify_ssl\n            )\n            \n            if response.status_code == 201:\n                self.token = response.text\n                self.session.headers.update({'Authorization': f'Bearer {self.token}'})\n                logger.info(\"Successfully authenticated with token\")\n            else:\n                logger.warning(f\"Token auth failed with status {response.status_code}\")\n                logger.warning(\"Falling back to basic auth\")\n                from requests.auth import HTTPBasicAuth\n                self.session.auth = HTTPBasicAuth(username, password)\n        except Exception as e:\n            logger.warning(f\"Token auth error: {e}, falling back to basic auth\")\n            from requests.auth import HTTPBasicAuth\n            self.session.auth = HTTPBasicAuth(username, password)\n    \n    def _request(self, method: str, endpoint: str, **kwargs) -> requests.Response:\n        \"\"\"Make authenticated request with 401 retry.\"\"\"\n        url = f\"{self.api_url}/{endpoint.lstrip('/')}\"\n        kwargs.setdefault('verify', self.verify_ssl)\n        \n        response = self.session.request(method, url, **kwargs)\n        \n        # Handle 401 by re-authenticating once\n        if response.status_code == 401:\n            logger.warning(\"Received 401, attempting re-authentication\")\n            self._authenticate(self.username, self.password)\n            response = self.session.request(method, url, **kwargs)\n            if response.status_code == 401:\n                raise Exception(\"Authentication failed: Unauthorized\")\n        \n        response.raise_for_status()\n        return response\n    \n    def get_process_group(self, group_id: str) -> Dict[str, Any]:\n        \"\"\"Get process group details including all processors.\"\"\"\n        response = self._request(\"GET\", f\"/flow/process-groups/{group_id}\")\n        return response.json()\n    \n    def list_processors(self, process_group_id: str) -> List[Dict[str, Any]]:\n        \"\"\"Get all processors in a process group (recursive).\"\"\"\n        pg_data = self.get_process_group(process_group_id)\n        processors = pg_data[\"processGroupFlow\"][\"flow\"][\"processors\"]\n        \n        # Recursively get processors from child groups\n        child_groups = pg_data[\"processGroupFlow\"][\"flow\"][\"processGroups\"]\n        for child in child_groups:\n            processors.extend(self.list_processors(child[\"id\"]))\n        \n        return processors\n    \n    def get_process_group_status(self, group_id: str) -> Dict[str, Any]:\n        \"\"\"Get execution statistics for process group.\"\"\"\n        response = self._request(\"GET\", f\"/flow/process-groups/{group_id}/status\")\n        return response.json()\n    \n    def get_processor_statistics(self, group_id: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Get processor-level statistics with IDs.\n        \n        SIMPLIFIED APPROACH:\n        1. Get processor list from Flow API (has IDs, names, types)\n        2. Get Status API and aggregate connections by processor name\n        3. Match by name to add IDs\n        \n        Returns:\n            List of processor dictionaries with IDs and aggregated metrics\n        \"\"\"\n        # Helper to safely convert to int\n        def safe_int(value, default=0):\n            \"\"\"Convert value to int, handling strings and None.\"\"\"\n            if value is None:\n                return default\n            try:\n                return int(value)\n            except (ValueError, TypeError):\n                return default\n        \n        # Step 1: Get processor list from Flow API (has IDs!)\n        processors = self.list_processors(group_id)\n        processor_lookup = {}\n        \n        for proc in processors:\n            component = proc.get('component', {})\n            proc_name = component.get('name')\n            proc_id = proc.get('id')\n            proc_type = component.get('type', '').split('.')[-1]\n            \n            processor_lookup[proc_name] = {\n                'id': proc_id,\n                'name': proc_name,\n                'type': proc_type\n            }\n        \n        logger.info(f\"Found {len(processor_lookup)} processors from Flow API\")\n        \n        # Step 2: Get Status API and aggregate by processor name\n        status_data = self.get_process_group_status(group_id)\n        processor_stats = {}\n        \n        def aggregate_connections(pg_status):\n            \"\"\"Recursively aggregate connection stats by source processor.\"\"\"\n            connection_statuses = pg_status.get(\"aggregateSnapshot\", {}).get(\"connectionStatusSnapshots\", [])\n            \n            for conn_status in connection_statuses:\n                conn_snap = conn_status.get(\"connectionStatusSnapshot\", {})\n                source_name = conn_snap.get('sourceName')\n                \n                if source_name:\n                    if source_name not in processor_stats:\n                        processor_stats[source_name] = {\n                            'flow_files_out': 0,\n                            'bytes_out': 0,\n                            'total_queued_count': 0,\n                            'total_queued_bytes': 0,\n                            'max_percent_use_count': 0\n                        }\n                    \n                    # Aggregate metrics with safe_int conversion\n                    processor_stats[source_name]['flow_files_out'] += safe_int(conn_snap.get('flowFilesOut', 0))\n                    processor_stats[source_name]['bytes_out'] += safe_int(conn_snap.get('bytesOut', 0))\n                    processor_stats[source_name]['total_queued_count'] += safe_int(conn_snap.get('queuedCount', 0))\n                    processor_stats[source_name]['total_queued_bytes'] += safe_int(conn_snap.get('queuedBytes', 0))\n                    processor_stats[source_name]['max_percent_use_count'] = max(\n                        processor_stats[source_name]['max_percent_use_count'],\n                        safe_int(conn_snap.get('percentUseCount', 0))\n                    )\n            \n            # Recurse into child groups\n            child_statuses = pg_status.get(\"processGroupStatus\", [])\n            for child_pg in child_statuses:\n                aggregate_connections(child_pg)\n        \n        pg_status = status_data.get(\"processGroupStatus\", {})\n        if pg_status:\n            aggregate_connections(pg_status)\n        \n        logger.info(f\"Aggregated stats for {len(processor_stats)} processors from Status API\")\n        \n        # Step 3: Merge - add IDs to stats\n        result = []\n        for proc_name, stats in processor_stats.items():\n            proc_info = processor_lookup.get(proc_name, {})\n            \n            result.append({\n                'processor_id': proc_info.get('id'),  # From Flow API\n                'processor_name': proc_name,\n                'processor_type': proc_info.get('type', 'Unknown'),\n                'flow_files_out': stats['flow_files_out'],\n                'bytes_out': stats['bytes_out'],\n                'total_queued_count': stats['total_queued_count'],\n                'total_queued_bytes': stats['total_queued_bytes'],\n                'max_percent_use_count': stats['max_percent_use_count']\n            })\n        \n        logger.info(f\"Returning {len(result)} processor records with IDs\")\n        return result\n    \n    def close(self):\n        \"\"\"Close session.\"\"\"\n        self.session.close()\n\nconsole.print(\"[green]✓ NiFiClient class defined (simplified processor-level)![/green]\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28f3c653-5945-470c-a95c-0dbfb7b60e29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# Cell 5: Multi-Flow Analyzer Class - SIMPLIFIED PROCESSOR-LEVEL\n\nclass MultiFlowAnalyzer:\n    \"\"\"Analyzes multiple NiFi flows and stores PROCESSOR-LEVEL results in Delta Lake.\"\"\"\n    \n    def __init__(self, client: NiFiClient, server: str = 'unknown'):\n        self.client = client\n        self.console = Console()\n        self.server = server\n        self.all_results = []\n        self.snapshot_timestamp = datetime.now()\n    \n    def analyze_flow(self, flow_id: str, flow_name: str) -> Dict:\n        \"\"\"Analyze a single flow - processor level.\"\"\"\n        flow_results = {\n            'flow_name': flow_name,\n            'flow_id': flow_id,\n            'processor_count': 0,\n            'processors': []\n        }\n        \n        try:\n            # Get processor-level statistics (SIMPLIFIED!)\n            processors = self.client.get_processor_statistics(flow_id)\n            flow_results['processor_count'] = len(processors)\n            \n            # Add metadata to each processor\n            for proc in processors:\n                flow_results['processors'].append({\n                    # Metadata (4 fields)\n                    'snapshot_timestamp': self.snapshot_timestamp,\n                    'server': self.server,\n                    'flow_name': flow_name,\n                    'process_group_id': flow_id,\n                    \n                    # Processor identity (3 fields)\n                    'processor_id': proc.get('processor_id'),\n                    'processor_name': proc.get('processor_name'),\n                    'processor_type': proc.get('processor_type'),\n                    \n                    # Aggregated metrics (4 fields)\n                    'flow_files_out': proc.get('flow_files_out', 0),\n                    'bytes_out': proc.get('bytes_out', 0),\n                    'total_queued_count': proc.get('total_queued_count', 0),\n                    'total_queued_bytes': proc.get('total_queued_bytes', 0),\n                    'max_percent_use_count': proc.get('max_percent_use_count', 0)\n                })\n            \n            return flow_results\n            \n        except Exception as e:\n            self.console.print(f\"[red]ERROR[/red] Failed to analyze {flow_name}: {e}\")\n            flow_results['error'] = str(e)\n            return flow_results\n    \n    def analyze_all_flows(self, flows_csv_path: str):\n        \"\"\"Analyze all flows from CSV.\"\"\"\n        self.console.print(f\"\\n[cyan]Multi-Flow Analysis Starting (PROCESSOR-LEVEL)...[/cyan]\")\n        self.console.print(f\"  Server: {self.server}\")\n        self.console.print(f\"  Timestamp: {self.snapshot_timestamp.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n        \n        # Read flows CSV\n        try:\n            flows_df = spark.read.csv(flows_csv_path, header=True)\n            flows = flows_df.collect()\n            \n            self.console.print(f\"[green]Found {len(flows)} flows to analyze[/green]\\n\")\n            \n        except Exception as e:\n            self.console.print(f\"[red]ERROR[/red] Failed to read CSV: {e}\")\n            raise\n        \n        # Analyze each flow\n        with Progress(\n            SpinnerColumn(),\n            TextColumn(\"[progress.description]{task.description}\"),\n            BarColumn(),\n            console=self.console\n        ) as progress:\n            task = progress.add_task(\"Analyzing flows...\", total=len(flows))\n            \n            for flow in flows:\n                flow_id = flow['id']\n                flow_name = flow['flow_name']\n                \n                progress.update(task, description=f\"Analyzing: {flow_name}\")\n                \n                flow_results = self.analyze_flow(flow_id, flow_name)\n                self.all_results.append(flow_results)\n                \n                # Display flow summary\n                if 'error' not in flow_results:\n                    self.console.print(\n                        f\"  [green]✓[/green] {flow_name}: {flow_results['processor_count']} processors\"\n                    )\n                else:\n                    self.console.print(\n                        f\"  [red]✗[/red] {flow_name}: {flow_results['error']}\"\n                    )\n                \n                progress.advance(task)\n        \n        # Display overall summary\n        self.display_summary()\n    \n    def display_summary(self):\n        \"\"\"Display analysis summary.\"\"\"\n        total_processors = sum(r['processor_count'] for r in self.all_results if 'error' not in r)\n        successful_flows = sum(1 for r in self.all_results if 'error' not in r)\n        failed_flows = sum(1 for r in self.all_results if 'error' in r)\n        \n        self.console.print(f\"\\n[cyan]Overall Summary:[/cyan]\")\n        self.console.print(f\"  Server: {self.server}\")\n        self.console.print(f\"  Total flows: {len(self.all_results)}\")\n        self.console.print(f\"  Successful: {successful_flows}\")\n        self.console.print(f\"  Failed: {failed_flows}\")\n        self.console.print(f\"  Total processors: {total_processors}\")\n        \n        # Create summary table\n        table = Table(title=\"\\nFlow Analysis Summary\")\n        table.add_column(\"Flow Name\", style=\"cyan\")\n        table.add_column(\"Processors\", justify=\"right\", style=\"yellow\")\n        table.add_column(\"Status\", style=\"green\")\n        \n        for result in self.all_results:\n            status = \"[red]Error[/red]\" if 'error' in result else \"[green]Success[/green]\"\n            table.add_row(\n                result['flow_name'],\n                str(result['processor_count']),\n                status\n            )\n        \n        self.console.print(table)\n    \n    def get_results_dataframe(self):\n        \"\"\"Convert all results to Spark DataFrame with SIMPLIFIED 11-field processor schema.\"\"\"\n        all_rows = []\n        \n        for flow_result in self.all_results:\n            if 'error' not in flow_result:\n                all_rows.extend(flow_result['processors'])\n        \n        if not all_rows:\n            return None\n        \n        # Helper function to safely convert to int\n        def safe_int(value, default=0):\n            \"\"\"Convert value to int, handling strings and None.\"\"\"\n            if value is None:\n                return default\n            try:\n                return int(value)\n            except (ValueError, TypeError):\n                return default\n        \n        # Convert to list of tuples (11 fields)\n        rows = [\n            (\n                row['snapshot_timestamp'],\n                row['server'],\n                row['flow_name'],\n                row['process_group_id'],\n                row['processor_id'],\n                row['processor_name'],\n                row['processor_type'],\n                safe_int(row['flow_files_out']),\n                safe_int(row['bytes_out']),\n                safe_int(row['total_queued_count']),\n                safe_int(row['max_percent_use_count'])\n            )\n            for row in all_rows\n        ]\n        \n        # Define SIMPLIFIED schema (11 fields - processor level)\n        schema = StructType([\n            # Metadata (4 fields)\n            StructField(\"snapshot_timestamp\", TimestampType(), False),\n            StructField(\"server\", StringType(), False),\n            StructField(\"flow_name\", StringType(), False),\n            StructField(\"process_group_id\", StringType(), False),\n            \n            # Processor identity (3 fields)\n            StructField(\"processor_id\", StringType(), True),\n            StructField(\"processor_name\", StringType(), False),\n            StructField(\"processor_type\", StringType(), True),\n            \n            # Aggregated metrics (4 fields)\n            StructField(\"flow_files_out\", LongType(), False),\n            StructField(\"bytes_out\", LongType(), False),\n            StructField(\"total_queued_count\", LongType(), False),\n            StructField(\"max_percent_use_count\", LongType(), False)\n        ])\n        \n        spark = SparkSession.builder.getOrCreate()\n        return spark.createDataFrame(rows, schema)\n\nconsole.print(\"[green]✓ MultiFlowAnalyzer class defined (simplified processor-level)![/green]\")"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16b0410c-171e-47c4-af2b-23e37969c8bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Starting Multi-Flow NiFi Analysis...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mStarting Multi-Flow NiFi Analysis\u001b[0m\u001b[36m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Connecting to NiFi...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mConnecting to NiFi\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:29,529 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:30,529 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:31,529 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:32,256 - nifi_analyzer - INFO - Successfully authenticated with token\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">OK</span> Connected successfully\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mOK\u001b[0m Connected successfully\n",
       "\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Multi-Flow Analysis Starting...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mMulti-Flow Analysis Starting\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Server: thailand\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Server: thailand\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Timestamp: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:57:32</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Timestamp: \u001b[1;36m2026\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m09\u001b[0m \u001b[1;92m18:57:32\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:32,528 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:32,771 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Found </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">31</span><span style=\"color: #008000; text-decoration-color: #008000\"> flows to analyze</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mFound \u001b[0m\u001b[1;32m31\u001b[0m\u001b[32m flows to analyze\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b25f76980ce4615a0916cf85abc4705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:33,528 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Data Monitoring: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Data Monitoring: \u001b[1;36m0\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Archive GTP landing zone: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Archive GTP landing zone: \u001b[1;36m34\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> ProbeADC v1: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m ProbeADC v1: \u001b[1;36m20\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Yesubabu - Test: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Yesubabu - Test: \u001b[1;36m0\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:34,528 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> WBAOI - POC: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m WBAOI - POC: \u001b[1;36m54\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Data Monitoring - Alert: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Data Monitoring - Alert: \u001b[1;36m0\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> SPC: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m SPC: \u001b[1;36m19\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Nutthawut - test: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Nutthawut - test: \u001b[1;36m0\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:35,528 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Landing AI: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Landing AI: \u001b[1;36m11\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Purging Data: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Purging Data: \u001b[1;36m0\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> ProbeADC v2: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m ProbeADC v2: \u001b[1;36m19\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> ProbeLog: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m ProbeLog: \u001b[1;36m23\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:36,528 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> AOI: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m AOI: \u001b[1;36m0\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> FDC Glue, Bonding  and Saw Configuration: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m FDC Glue, Bonding  and Saw Configuration: \u001b[1;36m0\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> DIDT: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m DIDT: \u001b[1;36m12\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> ACCT Dicer: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m ACCT Dicer: \u001b[1;36m60\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:37,529 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Dicer DC Curated: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Dicer DC Curated: \u001b[1;36m14\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> RPM v <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m RPM v \u001b[1;36m2.1\u001b[0m: \u001b[1;36m37\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:38,528 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> FDC Ingestion With Kafka PROD: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m FDC Ingestion With Kafka PROD: \u001b[1;36m2\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Srishti- Test: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Srishti- Test: \u001b[1;36m0\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> GTP v3: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m GTP v3: \u001b[1;36m15\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:39,529 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> RPM v <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m RPM v \u001b[1;36m2.0\u001b[0m: \u001b[1;36m39\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Dicer DC: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Dicer DC: \u001b[1;36m27\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:40,529 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> MES: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m MES: \u001b[1;36m32\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:41,528 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> RPM - Curated tables: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m RPM - Curated tables: \u001b[1;36m6\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> WBASM - POC: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m WBASM - POC: \u001b[1;36m23\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Chipsort: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Chipsort: \u001b[1;36m24\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:42,528 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> FDC Flows on NIFI Cluster : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m FDC Flows on NIFI Cluster : \u001b[1;36m0\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> MMS: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m MMS: \u001b[1;36m26\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Molding - POC: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Molding - POC: \u001b[1;36m28\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #008000; text-decoration-color: #008000\">✓</span> Dicer Log v3: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span> connections\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[32m✓\u001b[0m Dicer Log v3: \u001b[1;36m55\u001b[0m connections\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Overall Summary:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mOverall Summary:\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Server: thailand\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Server: thailand\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Total flows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Total flows: \u001b[1;36m31\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Successful: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Successful: \u001b[1;36m31\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Failed: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Failed: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Total connections: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">580</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Total connections: \u001b[1;36m580\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                                    </span>\n",
       "<span style=\"font-style: italic\">                       Flow Analysis Summary                        </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Flow Name                                </span>┃<span style=\"font-weight: bold\"> Connections </span>┃<span style=\"font-weight: bold\"> Status  </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Data Monitoring                          </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           0 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Archive GTP landing zone                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          34 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ProbeADC v1                              </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          20 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Yesubabu - Test                          </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           0 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> WBAOI - POC                              </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          54 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Data Monitoring - Alert                  </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           0 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> SPC                                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          19 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Nutthawut - test                         </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           0 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Landing AI                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          11 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Purging Data                             </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           0 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ProbeADC v2                              </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          19 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ProbeLog                                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          23 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> AOI                                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           0 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> FDC Glue, Bonding  and Saw Configuration </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           0 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> DIDT                                     </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          12 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ACCT Dicer                               </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          60 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Dicer DC Curated                         </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          14 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> RPM v 2.1                                </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          37 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> FDC Ingestion With Kafka PROD            </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           2 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Srishti- Test                            </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           0 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> GTP v3                                   </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          15 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> RPM v 2.0                                </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          39 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Dicer DC                                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          27 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> MES                                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          32 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> RPM - Curated tables                     </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           6 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> WBASM - POC                              </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          23 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Chipsort                                 </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          24 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> FDC Flows on NIFI Cluster                </span>│<span style=\"color: #808000; text-decoration-color: #808000\">           0 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> MMS                                      </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          26 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Molding - POC                            </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          28 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> Dicer Log v3                             </span>│<span style=\"color: #808000; text-decoration-color: #808000\">          55 </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> Success </span>│\n",
       "└──────────────────────────────────────────┴─────────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                                    \u001b[0m\n",
       "\u001b[3m                       Flow Analysis Summary                        \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mFlow Name                               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnections\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mStatus \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mData Monitoring                         \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          0\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mArchive GTP landing zone                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         34\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mProbeADC v1                             \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         20\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mYesubabu - Test                         \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          0\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mWBAOI - POC                             \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         54\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mData Monitoring - Alert                 \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          0\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSPC                                     \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         19\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mNutthawut - test                        \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          0\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mLanding AI                              \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         11\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mPurging Data                            \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          0\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mProbeADC v2                             \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         19\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mProbeLog                                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         23\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mAOI                                     \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          0\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mFDC Glue, Bonding  and Saw Configuration\u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          0\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mDIDT                                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         12\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mACCT Dicer                              \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         60\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mDicer DC Curated                        \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         14\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mRPM v 2.1                               \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         37\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mFDC Ingestion With Kafka PROD           \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          2\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSrishti- Test                           \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          0\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mGTP v3                                  \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         15\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mRPM v 2.0                               \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         39\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mDicer DC                                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         27\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mMES                                     \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         32\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mRPM - Curated tables                    \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          6\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mWBASM - POC                             \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         23\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mChipsort                                \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         24\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mFDC Flows on NIFI Cluster               \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m          0\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mMMS                                     \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         26\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mMolding - POC                           \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         28\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mDicer Log v3                            \u001b[0m\u001b[36m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m         55\u001b[0m\u001b[33m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mSuccess\u001b[0m\u001b[32m \u001b[0m│\n",
       "└──────────────────────────────────────────┴─────────────┴─────────┘\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">✓ Multi-flow analysis complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[32m✓ Multi-flow analysis complete!\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:43,539 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Run Multi-Flow Analysis\n",
    "\n",
    "console.print(\"\\n[cyan]Starting Multi-Flow NiFi Analysis...[/cyan]\\n\")\n",
    "\n",
    "# Connect to NiFi\n",
    "console.print(\"[yellow]Connecting to NiFi...[/yellow]\")\n",
    "client = NiFiClient(\n",
    "    base_url=CONFIG['nifi_url'],\n",
    "    username=CONFIG['username'],\n",
    "    password=CONFIG['password'],\n",
    "    verify_ssl=CONFIG['verify_ssl']\n",
    ")\n",
    "console.print(\"[green]OK[/green] Connected successfully\\n\")\n",
    "\n",
    "# Create analyzer and run analysis\n",
    "analyzer = MultiFlowAnalyzer(client=client, server=CONFIG['server'])\n",
    "analyzer.analyze_all_flows(CONFIG['flows_csv_path'])\n",
    "\n",
    "# Cleanup\n",
    "client.close()\n",
    "\n",
    "console.print(\"\\n[green]✓ Multi-flow analysis complete![/green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbb83d48-0627-44f1-af76-bcdc0fcc0d06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">Saving snapshots to Delta Lake...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[33mSaving snapshots to Delta Lake\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Table exists, appending data to: 1dp_mfg_sbx.validation_test_eric.nifi_processor_snapshots_full_attributes</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mTable exists, appending data to: 1dp_mfg_sbx.validation_test_eric.nifi_processor_snapshots_full_attributes\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:44,529 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:45,528 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">OK</span> Data appended successfully\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mOK\u001b[0m Data appended successfully\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Timestamp: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">18:57:32</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">260164</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Timestamp: \u001b[1;36m2026\u001b[0m-\u001b[1;36m01\u001b[0m-\u001b[1;36m09\u001b[0m \u001b[1;92m18:57:32\u001b[0m.\u001b[1;36m260164\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Total rows written: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">580</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  Total rows written: \u001b[1;36m580\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Sample data:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mSample data:\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>snapshot_timestamp</th><th>server</th><th>flow_name</th><th>process_group_id</th><th>connection_id</th><th>connection_name</th><th>connection_group_id</th><th>source_id</th><th>source_name</th><th>destination_id</th><th>destination_name</th><th>flow_files_in</th><th>flow_files_out</th><th>bytes_in</th><th>bytes_out</th><th>input</th><th>output</th><th>queued_count</th><th>queued_bytes</th><th>queued</th><th>queued_size</th><th>percent_use_count</th><th>percent_use_bytes</th><th>stats_last_refreshed</th></tr></thead><tbody><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>b516b8ea-cec7-3439-babd-d801bbfb97fe</td><td>success</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>NxpDateGenarator</td><td>null</td><td>UpdateAttribute - Site ATKH</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>f0d4163c-018f-1000-ffff-fffff6f56ded</td><td>output stream</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>Drop GTP Temp table partitions</td><td>null</td><td>LogAttribute</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>4815e136-775c-3e26-a2bd-cedc24f8e533</td><td>output stream</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>Check HAR file</td><td>null</td><td>Create folder in LZ</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>ed562cc5-27d3-32ae-821a-2dd49e976fe0</td><td>success</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>NxpDateGenarator</td><td>null</td><td>UpdateAttribute - Site ATTJ</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>03ed63eb-145a-330c-ae99-263b785e6bc2</td><td>success</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>UpdateAttribute - Site ATKH</td><td>null</td><td>Archive GTP file to landing-zone-har path</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>f0d3ff58-018f-1000-0000-00000368cee1</td><td>nonzero status</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>Drop GTP Temp table partitions</td><td>null</td><td>Retry 2 min</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>d956ca8a-cf00-3662-bc12-5687a8b57ec9</td><td>success</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>UpdateAttribute - Site ATKL</td><td>null</td><td>UpdateAttribute</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>a3460e90-937f-388b-8060-9d652f2e2a45</td><td>success</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>NxpDateGenarator</td><td>null</td><td>UpdateAttribute - Site ATKH</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>f141ab6b-f860-3286-9a6a-149a0eda9b28</td><td>success</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>UpdateAttribute - Site ATTJ</td><td>null</td><td>Archive GTP file to landing-zone-har path</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr><tr><td>2026-01-09T18:57:32.260164Z</td><td>thailand</td><td>Archive GTP landing zone</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>61fff9f5-27f9-3496-ae5c-fc2d2df5cbd0</td><td>success</td><td>bd78478d-0433-317d-9444-ac1518efc5ff</td><td>null</td><td>UpdateAttribute - Site ATTJ</td><td>null</td><td>Funnel</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 (0 bytes)</td><td>0</td><td>0</td><td>0 (0 bytes)</td><td>0 bytes</td><td>0</td><td>0</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "b516b8ea-cec7-3439-babd-d801bbfb97fe",
         "success",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "NxpDateGenarator",
         null,
         "UpdateAttribute - Site ATKH",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ],
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "f0d4163c-018f-1000-ffff-fffff6f56ded",
         "output stream",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "Drop GTP Temp table partitions",
         null,
         "LogAttribute",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ],
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "4815e136-775c-3e26-a2bd-cedc24f8e533",
         "output stream",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "Check HAR file",
         null,
         "Create folder in LZ",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ],
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "ed562cc5-27d3-32ae-821a-2dd49e976fe0",
         "success",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "NxpDateGenarator",
         null,
         "UpdateAttribute - Site ATTJ",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ],
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "03ed63eb-145a-330c-ae99-263b785e6bc2",
         "success",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "UpdateAttribute - Site ATKH",
         null,
         "Archive GTP file to landing-zone-har path",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ],
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "f0d3ff58-018f-1000-0000-00000368cee1",
         "nonzero status",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "Drop GTP Temp table partitions",
         null,
         "Retry 2 min",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ],
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "d956ca8a-cf00-3662-bc12-5687a8b57ec9",
         "success",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "UpdateAttribute - Site ATKL",
         null,
         "UpdateAttribute",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ],
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "a3460e90-937f-388b-8060-9d652f2e2a45",
         "success",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "NxpDateGenarator",
         null,
         "UpdateAttribute - Site ATKH",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ],
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "f141ab6b-f860-3286-9a6a-149a0eda9b28",
         "success",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "UpdateAttribute - Site ATTJ",
         null,
         "Archive GTP file to landing-zone-har path",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ],
        [
         "2026-01-09T18:57:32.260164Z",
         "thailand",
         "Archive GTP landing zone",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         "61fff9f5-27f9-3496-ae5c-fc2d2df5cbd0",
         "success",
         "bd78478d-0433-317d-9444-ac1518efc5ff",
         null,
         "UpdateAttribute - Site ATTJ",
         null,
         "Funnel",
         0,
         0,
         0,
         0,
         "0 (0 bytes)",
         "0 (0 bytes)",
         0,
         0,
         "0 (0 bytes)",
         "0 bytes",
         0,
         0,
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "snapshot_timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "server",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "flow_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "process_group_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "connection_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "connection_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "connection_group_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "destination_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "destination_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "flow_files_in",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "flow_files_out",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bytes_in",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bytes_out",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "input",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "output",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "queued_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "queued_bytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "queued",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "queued_size",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "percent_use_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "percent_use_bytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stats_last_refreshed",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     }
    }
   ],
   "source": [
    "# Cell 7: Save Snapshots to Delta Lake\n",
    "\n",
    "if CONFIG['enable_snapshots']:\n",
    "    console.print(\"\\n[yellow]Saving snapshots to Delta Lake...[/yellow]\")\n",
    "    \n",
    "    df = analyzer.get_results_dataframe()\n",
    "    \n",
    "    if df is not None:\n",
    "        table_name = CONFIG['delta_table_path']\n",
    "        \n",
    "        # Check if table exists\n",
    "        table_exists = spark.catalog._jcatalog.tableExists(table_name)\n",
    "        \n",
    "        if not table_exists:\n",
    "            # First run: Create table\n",
    "            console.print(f\"[yellow]Table doesn't exist, creating: {table_name}[/yellow]\")\n",
    "            df.write \\\n",
    "                .format(\"delta\") \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .option(\"overwriteSchema\", \"true\") \\\n",
    "                .saveAsTable(table_name)\n",
    "            console.print(f\"[green]OK[/green] Table created successfully with 24-field connection-level schema\")\n",
    "        else:\n",
    "            # Subsequent runs: Append data\n",
    "            console.print(f\"[yellow]Table exists, appending data to: {table_name}[/yellow]\")\n",
    "            df.write \\\n",
    "                .format(\"delta\") \\\n",
    "                .mode(\"append\") \\\n",
    "                .option(\"mergeSchema\", \"true\") \\\n",
    "                .saveAsTable(table_name)\n",
    "            console.print(f\"[green]OK[/green] Data appended successfully\")\n",
    "        \n",
    "        console.print(f\"  Timestamp: {analyzer.snapshot_timestamp}\")\n",
    "        console.print(f\"  Total rows written: {df.count()}\")\n",
    "        \n",
    "        # Show sample\n",
    "        console.print(f\"\\n[cyan]Sample data:[/cyan]\")\n",
    "        display(df.limit(10))\n",
    "    else:\n",
    "        console.print(\"[red]ERROR[/red] No data to save\")\n",
    "else:\n",
    "    console.print(\"\\n[yellow]Snapshots disabled[/yellow]\")\n",
    "\n",
    "# NOTE: If you need to manually drop the table to start fresh, run this in a separate cell:\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {CONFIG['delta_table_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4708d0b-7e63-4d7c-94d2-ec64adb24c7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">Querying connection-level snapshots...</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36mQuerying connection-level snapshots\u001b[0m\u001b[36m...\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Snapshot count by server and flow:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mSnapshot count by server and flow:\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:46,528 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:47,528 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:47,592 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+------------------------------------+---------+-----------------+--------------------------+\n|server  |flow_name                           |snapshots|total_connections|last_snapshot             |\n+--------+------------------------------------+---------+-----------------+--------------------------+\n|prod    |Database Ingest                     |1        |2                |2026-01-09 18:57:07.251193|\n|prod    |FDC Data Edge To Hadoop/Kafka       |1        |10               |2026-01-09 18:57:07.251193|\n|prod    |FDC Prod Data Processing            |1        |7                |2026-01-09 18:57:07.251193|\n|prod    |File Availability Metrics           |1        |2                |2026-01-09 18:57:07.251193|\n|prod    |File Ingest                         |1        |4                |2026-01-09 18:57:07.251193|\n|prod    |Final Test Bin SAF and STDF - Spark3|1        |2                |2026-01-09 18:57:07.251193|\n|prod    |Final Test TX SAF - Spark3          |1        |1                |2026-01-09 18:57:07.251193|\n|prod    |Final Test TX STDF - Spark3         |1        |46               |2026-01-09 18:57:07.251193|\n|prod    |ICN8 BRS Feedback                   |1        |40               |2026-01-09 18:57:07.251193|\n|prod    |ICN8 Track-out time based loading   |1        |46               |2026-01-09 18:57:07.251193|\n|prod    |Master Tables                       |1        |4                |2026-01-09 18:57:07.251193|\n|prod    |STDF Burn-in                        |1        |18               |2026-01-09 18:57:07.251193|\n|prod    |STDF Unit Probe Ingest              |1        |3                |2026-01-09 18:57:07.251193|\n|prod    |Saf Unit Probe                      |1        |3                |2026-01-09 18:57:07.251193|\n|thailand|ACCT Dicer                          |2        |120              |2026-01-09 18:57:32.260164|\n|thailand|Archive GTP landing zone            |2        |68               |2026-01-09 18:57:32.260164|\n|thailand|Chipsort                            |2        |48               |2026-01-09 18:57:32.260164|\n|thailand|DIDT                                |2        |24               |2026-01-09 18:57:32.260164|\n|thailand|Dicer DC                            |2        |54               |2026-01-09 18:57:32.260164|\n|thailand|Dicer DC Curated                    |2        |28               |2026-01-09 18:57:32.260164|\n+--------+------------------------------------+---------+-----------------+--------------------------+\nonly showing top 20 rows\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">Connections with queued flowfiles </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">backpressure</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[33mConnections with queued flowfiles \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mbackpressure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m:\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:48,024 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+---------------------------------+---------------------------------+-------------------------------+--------------------+----------------+----------------+\n|server|flow_name                        |source_name                      |destination_name               |max_queued_flowfiles|max_queued_bytes|max_percent_full|\n+------+---------------------------------+---------------------------------+-------------------------------+--------------------+----------------+----------------+\n|prod  |Final Test TX STDF - Spark3      |Try with more partitions and time|Catch errors                   |200                 |0               |1               |\n|prod  |Final Test TX STDF - Spark3      |Add new partition AWS Redshift   |Catch errors                   |70                  |0               |0               |\n|prod  |Final Test TX STDF - Spark3      |Split even/odd days              |Ingest stdf.stdf_ft_dp - Spark3|67                  |0               |1               |\n|prod  |ICN8 Track-out time based loading|Move file to \"processing\" folder |Dummy                          |23                  |0               |0               |\n|prod  |ICN8 BRS Feedback                |Funnel                           |Dummy                          |7                   |0               |0               |\n+------+---------------------------------+---------------------------------+-------------------------------+--------------------+----------------+----------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">Connections approaching queue limits </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">&gt;</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">50</span><span style=\"color: #808000; text-decoration-color: #808000\">% full</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[33mConnections approaching queue limits \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33m>\u001b[0m\u001b[1;33m50\u001b[0m\u001b[33m% full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m:\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+---------+-----------+----------------+----------------+----------------+\n|server|flow_name|source_name|destination_name|max_percent_full|max_queued_count|\n+------+---------+-----------+----------------+----------------+----------------+\n+------+---------+-----------+----------------+----------------+----------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">Inactive connections </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">no flowfiles for </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">7</span><span style=\"color: #808000; text-decoration-color: #808000\"> days</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[33mInactive connections \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mno flowfiles for \u001b[0m\u001b[1;33m7\u001b[0m\u001b[33m days\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m:\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:48,528 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:49,003 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----------------------------+---------------------------+------------------------+---------------+-------------+\n|server|flow_name                    |source_name                |destination_name        |delta_flowfiles|num_snapshots|\n+------+-----------------------------+---------------------------+------------------------+---------------+-------------+\n|prod  |Database Ingest              |from related tables trigger|from tx trigger         |0              |1            |\n|prod  |Database Ingest              |sleuth_ingest out          |sleuth_ingest           |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|ATBK Bridge To Kafka       |ATBK File Receiver      |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|ATBK Kafka Output          |ATBK Bridge To Kafka    |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|ATKH Bridge To Kafka       |ATKH File Receiver      |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|ATKH Kafka Output          |ATKH Bridge To Kafka    |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|ATKL Bridge To Kafka       |ATKL File Receiver      |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|ATKL Kafka Output          |ATKL Bridge To Kafka    |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|ATMC Bridge To Kafka       |ATMC File Receiver      |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|ATMC Kafka Output          |ATMC Bridge To Kafka    |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|CHD Bridge To Kafka        |CHD File Receiver       |0              |1            |\n|prod  |FDC Data Edge To Hadoop/Kafka|CHD Kafka Output           |CHD Bridge To Kafka     |0              |1            |\n|prod  |FDC Prod Data Processing     |Email Xinyu                |Failed, Resend in 30 min|0              |1            |\n|prod  |FDC Prod Data Processing     |Email Xinyu                |Done Email              |0              |1            |\n|prod  |FDC Prod Data Processing     |Failed, Resend in 30 min   |Email Xinyu             |0              |1            |\n|prod  |FDC Prod Data Processing     |Out For Email              |Email Xinyu             |0              |1            |\n|prod  |FDC Prod Data Processing     |Out For Email Notification |Email Xinyu             |0              |1            |\n|prod  |FDC Prod Data Processing     |Out For Error Notification |Email Xinyu             |0              |1            |\n|prod  |File Availability Metrics    |to_efars_load              |to_efars_load           |0              |1            |\n|prod  |File Availability Metrics    |to_hdfs_load               |to_hdfs_load            |0              |1            |\n+------+-----------------------------+---------------------------+------------------------+---------------+-------------+\nonly showing top 20 rows\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">Inactive processors by flow </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">aggregated from connections</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[33mInactive processors by flow \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33maggregated from connections\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m:\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:49,528 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:49,594 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+------------------------------------+------------------------+\n|server  |flow_name                           |inactive_processor_count|\n+--------+------------------------------------+------------------------+\n|prod    |ICN8 BRS Feedback                   |28                      |\n|prod    |ICN8 Track-out time based loading   |24                      |\n|prod    |STDF Burn-in                        |15                      |\n|prod    |Final Test TX STDF - Spark3         |13                      |\n|prod    |FDC Data Edge To Hadoop/Kafka       |10                      |\n|prod    |FDC Prod Data Processing            |5                       |\n|prod    |File Ingest                         |4                       |\n|prod    |Master Tables                       |4                       |\n|prod    |STDF Unit Probe Ingest              |3                       |\n|prod    |Final Test Bin SAF and STDF - Spark3|2                       |\n|prod    |Saf Unit Probe                      |2                       |\n|prod    |Database Ingest                     |2                       |\n|prod    |File Availability Metrics           |2                       |\n|prod    |Final Test TX SAF - Spark3          |1                       |\n|thailand|ACCT Dicer                          |23                      |\n|thailand|RPM v 2.0                           |22                      |\n|thailand|RPM v 2.1                           |21                      |\n|thailand|WBAOI - POC                         |21                      |\n|thailand|Chipsort                            |18                      |\n|thailand|Dicer Log v3                        |18                      |\n+--------+------------------------------------+------------------------+\nonly showing top 20 rows\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">Queue depth trends </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">hourly averages</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[33mQueue depth trends \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33mhourly averages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m:\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:50,091 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+------+---------------------------------+---------------------------------+-------------------------------+--------------------+--------------------+\n|hour               |server|flow_name                        |source_name                      |destination_name               |avg_queued_flowfiles|max_queued_flowfiles|\n+-------------------+------+---------------------------------+---------------------------------+-------------------------------+--------------------+--------------------+\n|2026-01-09 18:00:00|prod  |Final Test TX STDF - Spark3      |Try with more partitions and time|Catch errors                   |192.5               |200                 |\n|2026-01-09 18:00:00|prod  |Final Test TX STDF - Spark3      |Add new partition AWS Redshift   |Catch errors                   |70.0                |70                  |\n|2026-01-09 18:00:00|prod  |Final Test TX STDF - Spark3      |Split even/odd days              |Ingest stdf.stdf_ft_dp - Spark3|51.5                |67                  |\n|2026-01-09 18:00:00|prod  |ICN8 Track-out time based loading|Move file to \"processing\" folder |Dummy                          |23.0                |23                  |\n|2026-01-09 18:00:00|prod  |ICN8 BRS Feedback                |Funnel                           |Dummy                          |7.0                 |7                   |\n+-------------------+------+---------------------------------+---------------------------------+-------------------------------+--------------------+--------------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">Flow balance </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">input vs output by connection</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[33mFlow balance \u001b[0m\u001b[1;33m(\u001b[0m\u001b[33minput vs output by connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m:\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2026-01-09 18:57:50,528 - py4j.clientserver - INFO - Received command c on object id p0\n2026-01-09 18:57:50,661 - py4j.clientserver - INFO - Received command c on object id p0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+---------+-----------+----------------+------------------+-------------------+----------+\n|server|flow_name|source_name|destination_name|total_flowfiles_in|total_flowfiles_out|net_change|\n+------+---------+-----------+----------------+------------------+-------------------+----------+\n+------+---------+-----------+----------------+------------------+-------------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Query Historical Snapshots (Connection-Level Analysis)\n",
    "\n",
    "if CONFIG['enable_snapshots']:\n",
    "    console.print(\"\\n[cyan]Querying connection-level snapshots...[/cyan]\\n\")\n",
    "    \n",
    "    table_name = CONFIG['delta_table_path']\n",
    "    \n",
    "    try:\n",
    "        # Show snapshots per flow and server\n",
    "        console.print(\"[yellow]Snapshot count by server and flow:[/yellow]\")\n",
    "        spark.sql(f\"\"\"\n",
    "            SELECT \n",
    "                server,\n",
    "                flow_name,\n",
    "                COUNT(DISTINCT snapshot_timestamp) as snapshots,\n",
    "                COUNT(*) as total_connections,\n",
    "                MAX(snapshot_timestamp) as last_snapshot\n",
    "            FROM {table_name}\n",
    "            GROUP BY server, flow_name\n",
    "            ORDER BY server, flow_name\n",
    "        \"\"\").show(truncate=False)\n",
    "        \n",
    "        # NEW: Find connections with high queue depth (backpressure detection)\n",
    "        console.print(\"\\n[yellow]Connections with queued flowfiles (backpressure):[/yellow]\")\n",
    "        spark.sql(f\"\"\"\n",
    "            SELECT \n",
    "                server,\n",
    "                flow_name,\n",
    "                source_name,\n",
    "                destination_name,\n",
    "                MAX(queued_count) as max_queued_flowfiles,\n",
    "                MAX(queued_bytes) as max_queued_bytes,\n",
    "                MAX(percent_use_count) as max_percent_full\n",
    "            FROM {table_name}\n",
    "            WHERE queued_count > 0\n",
    "            GROUP BY server, flow_name, source_name, destination_name\n",
    "            ORDER BY max_queued_flowfiles DESC\n",
    "            LIMIT 20\n",
    "        \"\"\").show(truncate=False)\n",
    "        \n",
    "        # NEW: Identify connections approaching queue limits\n",
    "        console.print(\"\\n[yellow]Connections approaching queue limits (>50% full):[/yellow]\")\n",
    "        spark.sql(f\"\"\"\n",
    "            SELECT \n",
    "                server,\n",
    "                flow_name,\n",
    "                source_name,\n",
    "                destination_name,\n",
    "                MAX(percent_use_count) as max_percent_full,\n",
    "                MAX(queued_count) as max_queued_count\n",
    "            FROM {table_name}\n",
    "            WHERE percent_use_count > 50\n",
    "            GROUP BY server, flow_name, source_name, destination_name\n",
    "            ORDER BY max_percent_full DESC\n",
    "            LIMIT 20\n",
    "        \"\"\").show(truncate=False)\n",
    "        \n",
    "        # Find inactive connections (no flow for 7 days)\n",
    "        console.print(\"\\n[yellow]Inactive connections (no flowfiles for 7 days):[/yellow]\")\n",
    "        spark.sql(f\"\"\"\n",
    "            WITH connection_activity AS (\n",
    "                SELECT \n",
    "                    server,\n",
    "                    flow_name,\n",
    "                    source_name,\n",
    "                    destination_name,\n",
    "                    MAX(flow_files_out) - MIN(flow_files_out) as delta_flowfiles,\n",
    "                    MIN(snapshot_timestamp) as first_snapshot,\n",
    "                    MAX(snapshot_timestamp) as last_snapshot,\n",
    "                    COUNT(DISTINCT snapshot_timestamp) as num_snapshots\n",
    "                FROM {table_name}\n",
    "                WHERE snapshot_timestamp >= current_date() - INTERVAL 7 DAYS\n",
    "                GROUP BY server, flow_name, source_name, destination_name\n",
    "            )\n",
    "            SELECT \n",
    "                server,\n",
    "                flow_name,\n",
    "                source_name,\n",
    "                destination_name,\n",
    "                delta_flowfiles,\n",
    "                num_snapshots\n",
    "            FROM connection_activity\n",
    "            WHERE delta_flowfiles = 0\n",
    "            ORDER BY server, flow_name, source_name\n",
    "            LIMIT 50\n",
    "        \"\"\").show(truncate=False)\n",
    "        \n",
    "        # Aggregate to processor level (still possible!)\n",
    "        console.print(\"\\n[yellow]Inactive processors by flow (aggregated from connections):[/yellow]\")\n",
    "        spark.sql(f\"\"\"\n",
    "            WITH processor_activity AS (\n",
    "                SELECT \n",
    "                    server,\n",
    "                    flow_name,\n",
    "                    source_name as processor_name,\n",
    "                    MAX(flow_files_out) - MIN(flow_files_out) as delta_flowfiles\n",
    "                FROM {table_name}\n",
    "                WHERE snapshot_timestamp >= current_date() - INTERVAL 7 DAYS\n",
    "                GROUP BY server, flow_name, source_name\n",
    "            )\n",
    "            SELECT \n",
    "                server,\n",
    "                flow_name,\n",
    "                COUNT(*) as inactive_processor_count\n",
    "            FROM processor_activity\n",
    "            WHERE delta_flowfiles = 0\n",
    "            GROUP BY server, flow_name\n",
    "            ORDER BY server, inactive_processor_count DESC\n",
    "        \"\"\").show(truncate=False)\n",
    "        \n",
    "        # NEW: Track queue growth over time\n",
    "        console.print(\"\\n[yellow]Queue depth trends (hourly averages):[/yellow]\")\n",
    "        spark.sql(f\"\"\"\n",
    "            SELECT \n",
    "                DATE_TRUNC('hour', snapshot_timestamp) as hour,\n",
    "                server,\n",
    "                flow_name,\n",
    "                source_name,\n",
    "                destination_name,\n",
    "                AVG(queued_count) as avg_queued_flowfiles,\n",
    "                MAX(queued_count) as max_queued_flowfiles\n",
    "            FROM {table_name}\n",
    "            WHERE snapshot_timestamp >= current_date() - INTERVAL 1 DAYS\n",
    "              AND queued_count > 0\n",
    "            GROUP BY hour, server, flow_name, source_name, destination_name\n",
    "            ORDER BY hour DESC, avg_queued_flowfiles DESC\n",
    "            LIMIT 20\n",
    "        \"\"\").show(truncate=False)\n",
    "        \n",
    "        # NEW: Bidirectional flow analysis\n",
    "        console.print(\"\\n[yellow]Flow balance (input vs output by connection):[/yellow]\")\n",
    "        spark.sql(f\"\"\"\n",
    "            SELECT \n",
    "                server,\n",
    "                flow_name,\n",
    "                source_name,\n",
    "                destination_name,\n",
    "                SUM(flow_files_in) as total_flowfiles_in,\n",
    "                SUM(flow_files_out) as total_flowfiles_out,\n",
    "                SUM(flow_files_in) - SUM(flow_files_out) as net_change\n",
    "            FROM {table_name}\n",
    "            WHERE snapshot_timestamp >= current_date() - INTERVAL 7 DAYS\n",
    "            GROUP BY server, flow_name, source_name, destination_name\n",
    "            HAVING ABS(SUM(flow_files_in) - SUM(flow_files_out)) > 100\n",
    "            ORDER BY ABS(net_change) DESC\n",
    "            LIMIT 20\n",
    "        \"\"\").show(truncate=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]ERROR[/red] Failed to query: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    console.print(\"\\n[yellow]Snapshots disabled[/yellow]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baffe3ae-fe19-4192-b52d-ce7cc9760e1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Cell 9: Export Results to CSV by Flow\n",
    "\n",
    "# console.print(\"\\n[yellow]Exporting results to CSV...[/yellow]\")\n",
    "\n",
    "# timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# df = analyzer.get_results_dataframe()\n",
    "# if df is not None:\n",
    "#     pdf = df.toPandas()\n",
    "    \n",
    "#     # Export overall summary\n",
    "#     output_path = f\"/dbfs/nifi_analysis/all_flows_{timestamp_str}.csv\"\n",
    "#     pdf.to_csv(output_path, index=False)\n",
    "#     console.print(f\"[green]OK[/green] All flows exported to {output_path}\")\n",
    "    \n",
    "#     # Export per flow\n",
    "#     for flow_name in pdf['flow_name'].unique():\n",
    "#         flow_df = pdf[pdf['flow_name'] == flow_name]\n",
    "#         flow_path = f\"/dbfs/nifi_analysis/{flow_name}_{timestamp_str}.csv\"\n",
    "#         flow_df.to_csv(flow_path, index=False)\n",
    "#         console.print(f\"  [green]✓[/green] {flow_name}: {len(flow_df)} processors\")\n",
    "    \n",
    "#     console.print(f\"\\n[cyan]Sample data:[/cyan]\")\n",
    "#     display(pdf.head(10))\n",
    "# else:\n",
    "#     console.print(\"[red]ERROR[/red] No data to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4eb366b-247a-44ba-a9fa-fb29a19b9c73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Updated Delta Table Schema (Connection-Level)\n",
    "\n",
    "The Delta table now captures **ALL available fields** from NiFi Status API at the **connection level** (not processor level). This provides maximum granularity for analysis.\n",
    "\n",
    "### 24 Total Fields\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| **Metadata (4 fields)** | | |\n",
    "| `snapshot_timestamp` | Timestamp | When the snapshot was captured |\n",
    "| `server` | String | Server identifier (hostname, environment name) |\n",
    "| `flow_name` | String | Flow name from CSV |\n",
    "| `process_group_id` | String | NiFi process group ID |\n",
    "| **Connection Identity (3 fields)** | | |\n",
    "| `connection_id` | String | Connection UUID |\n",
    "| `connection_name` | String | Connection name (often empty or \"success\") |\n",
    "| `connection_group_id` | String | Parent process group ID |\n",
    "| **Source Processor (2 fields)** | | |\n",
    "| `source_id` | String | Source processor UUID |\n",
    "| `source_name` | String | Source processor name |\n",
    "| **Destination Processor (2 fields)** | | |\n",
    "| `destination_id` | String | Destination processor UUID |\n",
    "| `destination_name` | String | Destination processor name |\n",
    "| **Flow Metrics - 5-minute window (6 fields)** | | |\n",
    "| `flow_files_in` | Long | FlowFiles entering connection |\n",
    "| `flow_files_out` | Long | FlowFiles leaving connection |\n",
    "| `bytes_in` | Long | Bytes entering connection |\n",
    "| `bytes_out` | Long | Bytes leaving connection |\n",
    "| `input` | String | Formatted input stats (e.g., \"1,250 (50.8 KB)\") |\n",
    "| `output` | String | Formatted output stats |\n",
    "| **Queue Metrics - current state (4 fields)** | | |\n",
    "| `queued_count` | Long | FlowFiles currently queued |\n",
    "| `queued_bytes` | Long | Bytes currently queued |\n",
    "| `queued` | String | Formatted queue stats |\n",
    "| `queued_size` | String | Formatted queue size |\n",
    "| **Status Indicators (2 fields)** | | |\n",
    "| `percent_use_count` | Long | % of queue count threshold used |\n",
    "| `percent_use_bytes` | Long | % of queue bytes threshold used |\n",
    "| **Timestamps (1 field)** | | |\n",
    "| `stats_last_refreshed` | String | When stats were last updated |\n",
    "\n",
    "## Key Differences from Previous Version\n",
    "\n",
    "**Before:** 9 fields, processor-level aggregation\n",
    "- Only captured: flowFilesOut, bytesOut\n",
    "- Aggregated connections by source processor\n",
    "- Could not identify specific bottleneck connections\n",
    "- No queue monitoring capability\n",
    "\n",
    "**Now:** 24 fields, connection-level granularity\n",
    "- Captures ALL 15+ fields from NiFi Status API\n",
    "- Stores each connection separately\n",
    "- Can identify exact bottleneck points\n",
    "- Enables queue monitoring, backpressure detection, flow lineage\n",
    "\n",
    "**Impact:** ~2x more rows (typical NiFi flow has 1-2 connections per processor), but unlocks powerful new analysis capabilities.\n",
    "\n",
    "## New Analysis Capabilities\n",
    "\n",
    "### 1. Backpressure Detection\n",
    "Identify connections with high queue depth:\n",
    "```sql\n",
    "SELECT source_name, destination_name, MAX(queued_count) as max_queued\n",
    "FROM main.default.nifi_processor_snapshots\n",
    "WHERE queued_count > 100\n",
    "GROUP BY source_name, destination_name\n",
    "ORDER BY max_queued DESC;\n",
    "```\n",
    "\n",
    "### 2. Queue Limit Monitoring\n",
    "Find connections approaching capacity:\n",
    "```sql\n",
    "SELECT source_name, destination_name, MAX(percent_use_count) as max_percent_full\n",
    "FROM main.default.nifi_processor_snapshots\n",
    "WHERE percent_use_count > 80\n",
    "GROUP BY source_name, destination_name;\n",
    "```\n",
    "\n",
    "### 3. Bidirectional Flow Tracking\n",
    "Compare input vs output to find imbalances:\n",
    "```sql\n",
    "SELECT source_name,\n",
    "       SUM(flow_files_in) as total_in,\n",
    "       SUM(flow_files_out) as total_out,\n",
    "       SUM(flow_files_in) - SUM(flow_files_out) as net_change\n",
    "FROM main.default.nifi_processor_snapshots\n",
    "GROUP BY source_name\n",
    "HAVING ABS(net_change) > 100;\n",
    "```\n",
    "\n",
    "### 4. Queue Growth Trends\n",
    "Monitor queue depth over time:\n",
    "```sql\n",
    "SELECT DATE_TRUNC('hour', snapshot_timestamp) as hour,\n",
    "       source_name, destination_name,\n",
    "       AVG(queued_count) as avg_queued_flowfiles\n",
    "FROM main.default.nifi_processor_snapshots\n",
    "WHERE snapshot_timestamp >= current_date() - INTERVAL 1 DAYS\n",
    "GROUP BY hour, source_name, destination_name\n",
    "ORDER BY hour, avg_queued_flowfiles DESC;\n",
    "```\n",
    "\n",
    "### 5. Processor-Level Analysis (Still Possible!)\n",
    "Aggregate connections to processor-level when needed:\n",
    "```sql\n",
    "WITH processor_activity AS (\n",
    "    SELECT source_name,\n",
    "           MAX(flow_files_out) - MIN(flow_files_out) as delta\n",
    "    FROM main.default.nifi_processor_snapshots\n",
    "    WHERE snapshot_timestamp >= current_date() - INTERVAL 7 DAYS\n",
    "    GROUP BY source_name\n",
    ")\n",
    "SELECT * FROM processor_activity WHERE delta = 0;\n",
    "```\n",
    "\n",
    "### 6. Flow Path Lineage\n",
    "Track data movement through the flow:\n",
    "```sql\n",
    "SELECT source_name, destination_name, \n",
    "       SUM(flow_files_out) as total_flowfiles\n",
    "FROM main.default.nifi_processor_snapshots\n",
    "WHERE snapshot_timestamp >= current_date() - INTERVAL 7 DAYS\n",
    "GROUP BY source_name, destination_name\n",
    "ORDER BY total_flowfiles DESC;\n",
    "```\n",
    "\n",
    "## Unity Catalog Configuration\n",
    "\n",
    "The notebook uses Unity Catalog with 3-level naming:\n",
    "- **Catalog**: `main` (default)\n",
    "- **Schema**: `default` (default)\n",
    "- **Table**: `nifi_processor_snapshots`\n",
    "- **Full path**: `main.default.nifi_processor_snapshots`\n",
    "\n",
    "You can customize this in Cell 3 by editing `delta_table_path`.\n",
    "\n",
    "## CSV Format\n",
    "\n",
    "Your `flows.csv` should look like:\n",
    "```\n",
    "id,flow_name\n",
    "8c8677c4-29d6-3607-a32e-1234567890ab,Production_Data_Pipeline\n",
    "abc-123-def-456-7890-abcdef123456,Development_Testing_Flow\n",
    "xyz-789-ghi-012-3456-7890abcdef12,QA_Validation_Flow\n",
    "```\n",
    "\n",
    "Upload it to: `/dbfs/nifi_analysis/flows.csv`\n",
    "\n",
    "## Server Identifier\n",
    "\n",
    "The `server` field helps track data from multiple NiFi instances:\n",
    "- Use hostname: `prod-nifi-01`, `dev-nifi-02`\n",
    "- Use environment: `prod`, `dev`, `qa`, `staging`\n",
    "- Use datacenter: `dc1-nifi`, `dc2-nifi`\n",
    "\n",
    "This allows you to:\n",
    "- Compare processor usage across environments\n",
    "- Track migration from one server to another\n",
    "- Aggregate metrics across multiple NiFi clusters\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "**Connection-Level Storage:**\n",
    "- Each connection is stored as a separate row\n",
    "- Preserves source → destination relationships\n",
    "- Enables fine-grained debugging and analysis\n",
    "- Can still aggregate to processor-level in queries\n",
    "\n",
    "**Snapshot-based Analysis:**\n",
    "- Each run captures a snapshot of flowfile counts at that moment\n",
    "- Take snapshots every 5 minutes over a week\n",
    "- Calculate deltas (MAX - MIN) to identify inactive connections\n",
    "- Connection with delta = 0 means no flowfiles processed in that time period\n",
    "\n",
    "**Why Connection-Level Instead of Processor-Level?**\n",
    "- Identify which specific connection is bottlenecked\n",
    "- Monitor queue depth per connection\n",
    "- Track flow paths (source → destination lineage)\n",
    "- More debugging capability with minimal storage overhead\n",
    "\n",
    "**5-Minute Window:**\n",
    "- NiFi Status API returns metrics aggregated over the last 5 minutes\n",
    "- Running snapshots every 5 minutes captures distinct time windows\n",
    "- Historical data retained for 24 hours (configurable in NiFi)\n",
    "\n",
    "**Queue Metrics:**\n",
    "- `queued_count`: Current number of FlowFiles waiting in connection\n",
    "- `percent_use_count`: How full the queue is (approaching backpressure threshold)\n",
    "- Helps identify bottlenecks before they cause performance issues\n",
    "\n",
    "## Migration Notes\n",
    "\n",
    "**IMPORTANT:** Running Cell 7 will DROP the existing table to start fresh with the new 24-field schema. This is necessary because:\n",
    "1. Schema changed from 9 fields to 24 fields\n",
    "2. Data model changed from processor-level to connection-level\n",
    "3. Cannot merge old and new data structures\n",
    "\n",
    "**Before running:** If you want to preserve old data, create a backup:\n",
    "```python\n",
    "spark.sql(\"CREATE TABLE main.default.nifi_processor_snapshots_backup AS SELECT * FROM main.default.nifi_processor_snapshots\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nifi_analyzer_databricks_multi_flow_thailand",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NiFi Processor Analysis Dashboard\n",
    "\n",
    "Generate interactive HTML dashboard analyzing processor activity across NiFi flows.\n",
    "\n",
    "**Purpose**: Identify unused processors for cleanup/removal\n",
    "**Data Source**: Delta table `nifi_processor_snapshots_full_attributes`\n",
    "**Time Range**: Last 30 days\n",
    "**Output**: Interactive HTML dashboard with Plotly visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, sum as spark_sum, max as spark_max, min as spark_min, when, datediff, current_timestamp, lit\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration\n",
    "\n",
    "CONFIG = {\n",
    "    'table': '1dp_mfg_sbx.validation_test_eric.nifi_processor_snapshots_full_attributes',\n",
    "    'days_back': 30,\n",
    "    'output_file': '/Volumes/1dp_mfg_sbx/validation_test_eric/files/processor_analysis_dashboard.html',\n",
    "    'output_dir': '/Volumes/1dp_mfg_sbx/validation_test_eric/files/',\n",
    "    'inactive_threshold_pct': 1.0,  # <1% activity = inactive\n",
    "    'servers': None,  # None = all servers, or list like ['prod', 'thailand']\n",
    "}\n",
    "\n",
    "print(f\"‚úì Configuration loaded\")\n",
    "print(f\"  Table: {CONFIG['table']}\")\n",
    "print(f\"  Analysis period: Last {CONFIG['days_back']} days\")\n",
    "print(f\"  Output: {CONFIG['output_file']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Load Data from Delta Table (Optimized)\n\nprint(\"Loading data from Delta table...\")\n\n# Calculate cutoff date\ncutoff_date = (datetime.now() - timedelta(days=CONFIG['days_back'])).strftime('%Y-%m-%d')\nprint(f\"  Cutoff date: {cutoff_date}\")\n\n# Build query with server filter if needed\nwhere_clause = f\"WHERE snapshot_timestamp >= '{cutoff_date}'\"\nif CONFIG['servers']:\n    servers_filter = \"','\".join(CONFIG['servers'])\n    where_clause += f\" AND server IN ('{servers_filter}')\"\n\n# Get basic data stats (without loading all data)\nstats_query = f\"\"\"\n    SELECT \n        COUNT(*) as total_records,\n        COUNT(DISTINCT processor_id) as unique_processors,\n        COUNT(DISTINCT flow_name) as unique_flows,\n        COUNT(DISTINCT server) as unique_servers,\n        MIN(snapshot_timestamp) as earliest_snapshot,\n        MAX(snapshot_timestamp) as latest_snapshot\n    FROM {CONFIG['table']}\n    {where_clause}\n\"\"\"\n\nstats = spark.sql(stats_query).toPandas().iloc[0]\nprint(f\"‚úì Data overview:\")\nprint(f\"  Total records: {stats['total_records']:,}\")\nprint(f\"  Unique processors: {stats['unique_processors']}\")\nprint(f\"  Flows: {stats['unique_flows']}\")\nprint(f\"  Servers: {stats['unique_servers']}\")\nprint(f\"  Date range: {stats['earliest_snapshot']} to {stats['latest_snapshot']}\")\n\nprint(\"\\n‚ö†Ô∏è  Optimizing: Aggregating metrics in Spark SQL to avoid memory issues...\")\nprint(\"   (This may take a few minutes for large datasets)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: Calculate Processor Activity Metrics in Spark SQL\n\nprint(\"Calculating processor activity metrics in Spark SQL...\")\n\n# Calculate all processor metrics in a single Spark SQL query\nmetrics_query = f\"\"\"\nWITH processor_activity AS (\n    SELECT\n        server,\n        flow_name,\n        processor_id,\n        processor_name,\n        processor_type,\n        snapshot_timestamp,\n        flow_files_in,\n        flow_files_out,\n        bytes_in,\n        bytes_out,\n        tasks,\n        run_status,\n        CASE \n            WHEN flow_files_out > 0 OR tasks > 0 THEN 1 \n            ELSE 0 \n        END as has_activity\n    FROM {CONFIG['table']}\n    {where_clause}\n),\nprocessor_metrics AS (\n    SELECT\n        server,\n        flow_name,\n        processor_id,\n        processor_name,\n        processor_type,\n        COUNT(*) as total_snapshots,\n        SUM(has_activity) as snapshots_with_activity,\n        SUM(flow_files_in) as total_flowfiles_in,\n        SUM(flow_files_out) as total_flowfiles_out,\n        SUM(bytes_in) as total_bytes_in,\n        SUM(bytes_out) as total_bytes_out,\n        SUM(tasks) as total_tasks,\n        MAX(CASE WHEN has_activity = 1 THEN snapshot_timestamp END) as last_active_time,\n        MAX(run_status) as last_run_status\n    FROM processor_activity\n    GROUP BY server, flow_name, processor_id, processor_name, processor_type\n)\nSELECT\n    server,\n    flow_name,\n    processor_id,\n    processor_name,\n    processor_type,\n    total_snapshots,\n    snapshots_with_activity,\n    total_flowfiles_in,\n    total_flowfiles_out,\n    total_bytes_in,\n    total_bytes_out,\n    total_tasks,\n    last_active_time,\n    last_run_status,\n    ROUND((snapshots_with_activity * 100.0 / total_snapshots), 2) as activity_rate_pct,\n    COALESCE(DATEDIFF(CURRENT_TIMESTAMP(), last_active_time), {CONFIG['days_back']}) as days_since_active,\n    CASE\n        WHEN last_run_status != 'Running' THEN 'Stopped'\n        WHEN snapshots_with_activity = 0 THEN 'Inactive'\n        WHEN (snapshots_with_activity * 100.0 / total_snapshots) < {CONFIG['inactive_threshold_pct']} THEN 'Low Activity'\n        ELSE 'Active'\n    END as activity_status,\n    CASE\n        WHEN last_run_status != 'Running' AND snapshots_with_activity = 0 THEN 'Remove'\n        WHEN snapshots_with_activity = 0 THEN 'Remove'\n        WHEN (snapshots_with_activity * 100.0 / total_snapshots) < {CONFIG['inactive_threshold_pct']} THEN 'Review'\n        ELSE 'Keep'\n    END as recommendation,\n    CASE\n        WHEN snapshots_with_activity = 0 THEN '0 (Never)'\n        WHEN snapshots_with_activity <= 100 THEN '1-100 (Rarely)'\n        WHEN snapshots_with_activity <= 1000 THEN '101-1000 (Occasionally)'\n        WHEN snapshots_with_activity <= 4000 THEN '1001-4000 (Regularly)'\n        ELSE '4000+ (Constantly)'\n    END as activity_bucket\nFROM processor_metrics\nORDER BY server, flow_name, activity_rate_pct\n\"\"\"\n\n# Execute query and convert only the aggregated results to Pandas\nprocessor_metrics = spark.sql(metrics_query).toPandas()\n\nprint(f\"‚úì Calculated metrics for {len(processor_metrics)} processors\")\nprint(f\"\\nActivity Status Distribution:\")\nprint(processor_metrics['activity_status'].value_counts())\nprint(f\"\\nRecommendations:\")\nprint(processor_metrics['recommendation'].value_counts())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Helper Functions for Visualizations\n",
    "\n",
    "def create_summary_cards(metrics_df):\n",
    "    \"\"\"Create executive summary metrics.\"\"\"\n",
    "    total_processors = len(metrics_df)\n",
    "    inactive_processors = len(metrics_df[metrics_df['activity_status'].isin(['Inactive', 'Stopped'])])\n",
    "    cleanup_candidates = len(metrics_df[metrics_df['recommendation'] == 'Remove'])\n",
    "    review_required = len(metrics_df[metrics_df['recommendation'] == 'Review'])\n",
    "    flows_analyzed = metrics_df['flow_name'].nunique()\n",
    "    servers = metrics_df['server'].unique().tolist()\n",
    "    \n",
    "    cleanup_impact_pct = (cleanup_candidates / total_processors * 100) if total_processors > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_processors': total_processors,\n",
    "        'inactive_processors': inactive_processors,\n",
    "        'cleanup_candidates': cleanup_candidates,\n",
    "        'review_required': review_required,\n",
    "        'flows_analyzed': flows_analyzed,\n",
    "        'servers': servers,\n",
    "        'cleanup_impact_pct': round(cleanup_impact_pct, 1),\n",
    "        'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "\n",
    "def create_status_badge(status):\n",
    "    \"\"\"Create HTML status badge.\"\"\"\n",
    "    colors = {\n",
    "        'Active': '#28a745',\n",
    "        'Low Activity': '#ffc107',\n",
    "        'Inactive': '#dc3545',\n",
    "        'Stopped': '#6c757d'\n",
    "    }\n",
    "    emojis = {\n",
    "        'Active': 'üü¢',\n",
    "        'Low Activity': 'üü°',\n",
    "        'Inactive': 'üî¥',\n",
    "        'Stopped': '‚ö´'\n",
    "    }\n",
    "    color = colors.get(status, '#6c757d')\n",
    "    emoji = emojis.get(status, '‚ö´')\n",
    "    return f'{emoji} <span style=\"color:{color};font-weight:bold;\">{status}</span>'\n",
    "\n",
    "def create_recommendation_badge(rec):\n",
    "    \"\"\"Create HTML recommendation badge.\"\"\"\n",
    "    colors = {\n",
    "        'Keep': '#28a745',\n",
    "        'Review': '#ffc107',\n",
    "        'Remove': '#dc3545'\n",
    "    }\n",
    "    symbols = {\n",
    "        'Keep': '‚úì',\n",
    "        'Review': '‚ö†Ô∏è',\n",
    "        'Remove': '‚ùå'\n",
    "    }\n",
    "    color = colors.get(rec, '#6c757d')\n",
    "    symbol = symbols.get(rec, '?')\n",
    "    return f'{symbol} <span style=\"color:{color};font-weight:bold;\">{rec}</span>'\n",
    "\n",
    "print(\"‚úì Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create Executive Summary Visualizations\n",
    "\n",
    "print(\"Creating executive summary visualizations...\")\n",
    "\n",
    "summary = create_summary_cards(processor_metrics)\n",
    "\n",
    "# Pie chart: Active vs Inactive\n",
    "status_counts = processor_metrics['activity_status'].value_counts()\n",
    "fig_pie = go.Figure(data=[go.Pie(\n",
    "    labels=status_counts.index,\n",
    "    values=status_counts.values,\n",
    "    marker=dict(colors=['#28a745', '#ffc107', '#dc3545', '#6c757d']),\n",
    "    hole=0.4\n",
    ")])\n",
    "fig_pie.update_layout(\n",
    "    title=\"Processor Status Distribution\",\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Bar chart: Top flows by processor count\n",
    "flow_summary = processor_metrics.groupby('flow_name').agg({\n",
    "    'processor_id': 'count',\n",
    "    'activity_status': lambda x: (x.isin(['Inactive', 'Stopped'])).sum()\n",
    "}).reset_index()\n",
    "flow_summary.columns = ['flow_name', 'total_processors', 'inactive_processors']\n",
    "flow_summary['active_processors'] = flow_summary['total_processors'] - flow_summary['inactive_processors']\n",
    "flow_summary = flow_summary.sort_values('total_processors', ascending=False).head(10)\n",
    "\n",
    "fig_bar = go.Figure()\n",
    "fig_bar.add_trace(go.Bar(\n",
    "    name='Active',\n",
    "    x=flow_summary['flow_name'],\n",
    "    y=flow_summary['active_processors'],\n",
    "    marker_color='#28a745'\n",
    "))\n",
    "fig_bar.add_trace(go.Bar(\n",
    "    name='Inactive',\n",
    "    x=flow_summary['flow_name'],\n",
    "    y=flow_summary['inactive_processors'],\n",
    "    marker_color='#dc3545'\n",
    "))\n",
    "fig_bar.update_layout(\n",
    "    title=\"Top 10 Flows by Processor Count\",\n",
    "    barmode='stack',\n",
    "    xaxis_title=\"Flow Name\",\n",
    "    yaxis_title=\"Processor Count\",\n",
    "    height=400,\n",
    "    xaxis_tickangle=-45\n",
    ")\n",
    "\n",
    "print(\"‚úì Executive summary visualizations created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: Create Per-Flow Visualizations\n\ndef create_flow_histogram(flow_data):\n    \"\"\"Create activity frequency histogram for a flow.\"\"\"\n    bucket_counts = flow_data['activity_bucket'].value_counts().reindex([\n        '0 (Never)', '1-100 (Rarely)', '101-1000 (Occasionally)',\n        '1001-4000 (Regularly)', '4000+ (Constantly)'\n    ], fill_value=0)\n    \n    colors = ['#dc3545', '#fd7e14', '#ffc107', '#90EE90', '#28a745']\n    \n    fig = go.Figure(data=[go.Bar(\n        x=bucket_counts.index,\n        y=bucket_counts.values,\n        marker_color=colors,\n        text=bucket_counts.values,\n        textposition='auto'\n    )])\n    \n    fig.update_layout(\n        title=\"Processor Activity Frequency\",\n        xaxis_title=\"Activity Level\",\n        yaxis_title=\"Number of Processors\",\n        height=350,\n        showlegend=False\n    )\n    \n    return fig\n\ndef create_flow_timeline(flow_name, flow_server):\n    \"\"\"Create activity timeline for a flow - loads data on-demand.\"\"\"\n    # Query only this flow's daily aggregated data\n    timeline_query = f\"\"\"\n    SELECT\n        processor_name,\n        DATE_TRUNC('day', snapshot_timestamp) as day,\n        SUM(flow_files_out) as daily_flowfiles,\n        SUM(tasks) as daily_tasks\n    FROM {CONFIG['table']}\n    {where_clause}\n        AND flow_name = '{flow_name}'\n        AND server = '{flow_server}'\n    GROUP BY processor_name, DATE_TRUNC('day', snapshot_timestamp)\n    ORDER BY processor_name, day\n    \"\"\"\n    \n    daily = spark.sql(timeline_query).toPandas()\n    \n    if daily.empty:\n        # Return empty figure if no data\n        fig = go.Figure()\n        fig.update_layout(title=\"No activity data available\", height=200)\n        return fig\n    \n    # Convert day to date for pivoting\n    daily['day'] = pd.to_datetime(daily['day']).dt.date\n    \n    # Create heatmap\n    pivot = daily.pivot(index='processor_name', columns='day', values='daily_flowfiles').fillna(0)\n    \n    fig = go.Figure(data=go.Heatmap(\n        z=pivot.values,\n        x=pivot.columns,\n        y=pivot.index,\n        colorscale='YlGnBu',\n        hovertemplate='Processor: %{y}<br>Date: %{x}<br>FlowFiles: %{z}<extra></extra>'\n    ))\n    \n    fig.update_layout(\n        title=\"Processor Activity Timeline (Daily)\",\n        xaxis_title=\"Date\",\n        yaxis_title=\"Processor\",\n        height=max(400, len(pivot) * 20)  # Scale height with processor count\n    )\n    \n    return fig\n\ndef create_processor_type_chart(flow_data):\n    \"\"\"Create processor type distribution chart.\"\"\"\n    type_summary = flow_data.groupby(['processor_type', 'activity_status']).size().reset_index(name='count')\n    \n    # Separate active and inactive\n    active_df = type_summary[type_summary['activity_status'] == 'Active']\n    inactive_df = type_summary[type_summary['activity_status'].isin(['Inactive', 'Stopped', 'Low Activity'])]\n    \n    fig = go.Figure()\n    \n    if not active_df.empty:\n        fig.add_trace(go.Bar(\n            name='Active',\n            x=active_df['processor_type'],\n            y=active_df['count'],\n            marker_color='#28a745'\n        ))\n    \n    if not inactive_df.empty:\n        inactive_grouped = inactive_df.groupby('processor_type')['count'].sum().reset_index()\n        fig.add_trace(go.Bar(\n            name='Inactive',\n            x=inactive_grouped['processor_type'],\n            y=inactive_grouped['count'],\n            marker_color='#dc3545'\n        ))\n    \n    fig.update_layout(\n        title=\"Processor Type Distribution\",\n        barmode='stack',\n        xaxis_title=\"Processor Type\",\n        yaxis_title=\"Count\",\n        height=350,\n        xaxis_tickangle=-45\n    )\n    \n    return fig\n\nprint(\"‚úì Per-flow visualization functions defined\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Generate HTML Dashboard\n",
    "\n",
    "print(\"Generating HTML dashboard...\")\n",
    "\n",
    "# Start building HTML\n",
    "html_parts = []\n",
    "\n",
    "# HTML header\n",
    "html_parts.append(\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>NiFi Processor Analysis Dashboard</title>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 20px;\n",
    "            background-color: #f5f5f5;\n",
    "        }\n",
    "        .container {\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "            background-color: white;\n",
    "            padding: 30px;\n",
    "            box-shadow: 0 0 10px rgba(0,0,0,0.1);\n",
    "        }\n",
    "        h1 {\n",
    "            color: #333;\n",
    "            border-bottom: 3px solid #007bff;\n",
    "            padding-bottom: 10px;\n",
    "        }\n",
    "        h2 {\n",
    "            color: #0056b3;\n",
    "            margin-top: 30px;\n",
    "            border-left: 4px solid #007bff;\n",
    "            padding-left: 10px;\n",
    "        }\n",
    "        h3 {\n",
    "            color: #495057;\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        .summary-cards {\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
    "            gap: 20px;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        .card {\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "        }\n",
    "        .card-title {\n",
    "            font-size: 14px;\n",
    "            opacity: 0.9;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "        .card-value {\n",
    "            font-size: 32px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .card.red {\n",
    "            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n",
    "        }\n",
    "        .card.green {\n",
    "            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);\n",
    "        }\n",
    "        .card.yellow {\n",
    "            background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);\n",
    "        }\n",
    "        .flow-section {\n",
    "            margin: 40px 0;\n",
    "            border: 1px solid #dee2e6;\n",
    "            border-radius: 8px;\n",
    "            padding: 20px;\n",
    "            background-color: #f8f9fa;\n",
    "        }\n",
    "        .flow-header {\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            align-items: center;\n",
    "            cursor: pointer;\n",
    "            padding: 10px;\n",
    "            background-color: #e9ecef;\n",
    "            border-radius: 5px;\n",
    "            margin-bottom: 15px;\n",
    "        }\n",
    "        .flow-header:hover {\n",
    "            background-color: #dee2e6;\n",
    "        }\n",
    "        .flow-content {\n",
    "            display: block;\n",
    "        }\n",
    "        table {\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            margin: 20px 0;\n",
    "            background-color: white;\n",
    "        }\n",
    "        th, td {\n",
    "            padding: 12px;\n",
    "            text-align: left;\n",
    "            border-bottom: 1px solid #dee2e6;\n",
    "        }\n",
    "        th {\n",
    "            background-color: #007bff;\n",
    "            color: white;\n",
    "            font-weight: bold;\n",
    "            position: sticky;\n",
    "            top: 0;\n",
    "        }\n",
    "        tr:hover {\n",
    "            background-color: #f8f9fa;\n",
    "        }\n",
    "        .chart-container {\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        .timestamp {\n",
    "            color: #6c757d;\n",
    "            font-size: 14px;\n",
    "            margin-top: 10px;\n",
    "        }\n",
    "        .nav-menu {\n",
    "            background-color: #343a40;\n",
    "            padding: 15px;\n",
    "            border-radius: 5px;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "        .nav-menu a {\n",
    "            color: white;\n",
    "            text-decoration: none;\n",
    "            padding: 8px 15px;\n",
    "            margin: 0 5px;\n",
    "            border-radius: 3px;\n",
    "            display: inline-block;\n",
    "        }\n",
    "        .nav-menu a:hover {\n",
    "            background-color: #495057;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"container\">\n",
    "    <h1>üìä NiFi Processor Analysis Dashboard</h1>\n",
    "    <p class=\"timestamp\">Generated: \"\"\" + summary['last_update'] + \"\"\"</p>\n",
    "    <p class=\"timestamp\">Analysis Period: Last \"\"\" + str(CONFIG['days_back']) + \"\"\" days</p>\n",
    "\"\"\")\n",
    "\n",
    "# Executive Summary Cards\n",
    "html_parts.append(\"\"\"\n",
    "    <h2>Executive Summary</h2>\n",
    "    <div class=\"summary-cards\">\n",
    "        <div class=\"card green\">\n",
    "            <div class=\"card-title\">Total Processors</div>\n",
    "            <div class=\"card-value\">\"\"\" + str(summary['total_processors']) + \"\"\"</div>\n",
    "        </div>\n",
    "        <div class=\"card red\">\n",
    "            <div class=\"card-title\">Inactive Processors</div>\n",
    "            <div class=\"card-value\">\"\"\" + str(summary['inactive_processors']) + \"\"\"</div>\n",
    "        </div>\n",
    "        <div class=\"card red\">\n",
    "            <div class=\"card-title\">Cleanup Candidates</div>\n",
    "            <div class=\"card-value\">\"\"\" + str(summary['cleanup_candidates']) + \"\"\"</div>\n",
    "        </div>\n",
    "        <div class=\"card yellow\">\n",
    "            <div class=\"card-title\">Review Required</div>\n",
    "            <div class=\"card-value\">\"\"\" + str(summary['review_required']) + \"\"\"</div>\n",
    "        </div>\n",
    "        <div class=\"card green\">\n",
    "            <div class=\"card-title\">Flows Analyzed</div>\n",
    "            <div class=\"card-value\">\"\"\" + str(summary['flows_analyzed']) + \"\"\"</div>\n",
    "        </div>\n",
    "        <div class=\"card\">\n",
    "            <div class=\"card-title\">Cleanup Impact</div>\n",
    "            <div class=\"card-value\">\"\"\" + str(summary['cleanup_impact_pct']) + \"\"\"%</div>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\")\n",
    "\n",
    "# Add executive summary charts\n",
    "html_parts.append('<div class=\"chart-container\">')\n",
    "html_parts.append(fig_pie.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "html_parts.append('</div>')\n",
    "\n",
    "html_parts.append('<div class=\"chart-container\">')\n",
    "html_parts.append(fig_bar.to_html(full_html=False, include_plotlyjs=False))\n",
    "html_parts.append('</div>')\n",
    "\n",
    "print(\"‚úì Executive summary section created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 9: Generate Per-Flow Sections\n\nprint(\"Generating per-flow sections...\")\n\nflows = processor_metrics[['server', 'flow_name']].drop_duplicates().values\n\nfor i, (flow_server, flow_name) in enumerate(flows, 1):\n    print(f\"  Processing {i}/{len(flows)}: {flow_name} ({flow_server})\")\n    \n    flow_data = processor_metrics[(processor_metrics['flow_name'] == flow_name) & \n                                   (processor_metrics['server'] == flow_server)].copy()\n    \n    total_procs = len(flow_data)\n    inactive_procs = len(flow_data[flow_data['activity_status'].isin(['Inactive', 'Stopped'])])\n    \n    # Flow section header\n    html_parts.append(f\"\"\"\n    <div class=\"flow-section\" id=\"flow-{i}\">\n        <div class=\"flow-header\" onclick=\"toggleFlow({i})\">\n            <h3>üìÅ {flow_name} ({flow_server})</h3>\n            <div>\n                <span style=\"margin-right:20px;\">Total: {total_procs} | Inactive: {inactive_procs}</span>\n                <span id=\"toggle-{i}\">‚ñº</span>\n            </div>\n        </div>\n        <div class=\"flow-content\" id=\"content-{i}\">\n    \"\"\")\n    \n    # Activity histogram\n    fig_hist = create_flow_histogram(flow_data)\n    html_parts.append('<div class=\"chart-container\">')\n    html_parts.append(fig_hist.to_html(full_html=False, include_plotlyjs=False))\n    html_parts.append('</div>')\n    \n    # Activity timeline (loads data on-demand to save memory)\n    fig_timeline = create_flow_timeline(flow_name, flow_server)\n    html_parts.append('<div class=\"chart-container\">')\n    html_parts.append(fig_timeline.to_html(full_html=False, include_plotlyjs=False))\n    html_parts.append('</div>')\n    \n    # Processor type distribution\n    fig_types = create_processor_type_chart(flow_data)\n    html_parts.append('<div class=\"chart-container\">')\n    html_parts.append(fig_types.to_html(full_html=False, include_plotlyjs=False))\n    html_parts.append('</div>')\n    \n    # Processor details table\n    html_parts.append('<h4>Processor Details</h4>')\n    html_parts.append('<table>')\n    html_parts.append('<tr>')\n    html_parts.append('<th>Processor Name</th>')\n    html_parts.append('<th>Type</th>')\n    html_parts.append('<th>Status</th>')\n    html_parts.append('<th>Activity %</th>')\n    html_parts.append('<th>FlowFiles (30d)</th>')\n    html_parts.append('<th>Tasks (30d)</th>')\n    html_parts.append('<th>Days Since Active</th>')\n    html_parts.append('<th>Recommendation</th>')\n    html_parts.append('</tr>')\n    \n    # Sort by activity rate (inactive first)\n    flow_data_sorted = flow_data.sort_values('activity_rate_pct')\n    \n    for _, row in flow_data_sorted.iterrows():\n        html_parts.append('<tr>')\n        html_parts.append(f'<td>{row[\"processor_name\"]}</td>')\n        html_parts.append(f'<td>{row[\"processor_type\"]}</td>')\n        html_parts.append(f'<td>{create_status_badge(row[\"activity_status\"])}</td>')\n        html_parts.append(f'<td>{row[\"activity_rate_pct\"]:.2f}%</td>')\n        html_parts.append(f'<td>{int(row[\"total_flowfiles_out\"]):,}</td>')\n        html_parts.append(f'<td>{int(row[\"total_tasks\"]):,}</td>')\n        html_parts.append(f'<td>{int(row[\"days_since_active\"])}</td>')\n        html_parts.append(f'<td>{create_recommendation_badge(row[\"recommendation\"])}</td>')\n        html_parts.append('</tr>')\n    \n    html_parts.append('</table>')\n    html_parts.append('</div></div>')  # Close flow-content and flow-section\n\nprint(\"‚úì Per-flow sections created\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 10: Add Cleanup Recommendations Section\n\nprint(\"Creating cleanup recommendations section...\")\n\nhtml_parts.append(\"\"\"\n    <h2>üßπ Cleanup Recommendations</h2>\n\"\"\")\n\n# High-priority removals\nremove_list = processor_metrics[processor_metrics['recommendation'] == 'Remove'].copy()\nhtml_parts.append(f'<h3>High-Priority Removals ({len(remove_list)} processors)</h3>')\nhtml_parts.append('<p>These processors have zero activity and can be safely removed:</p>')\n\nif len(remove_list) > 0:\n    html_parts.append('<table>')\n    html_parts.append('<tr><th>Flow</th><th>Processor Name</th><th>Type</th><th>Run Status</th><th>Days Inactive</th></tr>')\n    for _, row in remove_list.iterrows():\n        html_parts.append(f'<tr>')\n        html_parts.append(f'<td>{row[\"flow_name\"]}</td>')\n        html_parts.append(f'<td>{row[\"processor_name\"]}</td>')\n        html_parts.append(f'<td>{row[\"processor_type\"]}</td>')\n        html_parts.append(f'<td>{row[\"last_run_status\"]}</td>')\n        html_parts.append(f'<td>{int(row[\"days_since_active\"])}</td>')\n        html_parts.append('</tr>')\n    html_parts.append('</table>')\nelse:\n    html_parts.append('<p>‚úì No processors recommended for removal!</p>')\n\n# Review required\nreview_list = processor_metrics[processor_metrics['recommendation'] == 'Review'].copy()\nhtml_parts.append(f'<h3>Review Required ({len(review_list)} processors)</h3>')\nhtml_parts.append('<p>These processors have low activity and should be reviewed manually:</p>')\n\nif len(review_list) > 0:\n    html_parts.append('<table>')\n    html_parts.append('<tr><th>Flow</th><th>Processor Name</th><th>Type</th><th>Activity %</th><th>Total Tasks</th></tr>')\n    for _, row in review_list.head(20).iterrows():  # Limit to 20\n        html_parts.append(f'<tr>')\n        html_parts.append(f'<td>{row[\"flow_name\"]}</td>')\n        html_parts.append(f'<td>{row[\"processor_name\"]}</td>')\n        html_parts.append(f'<td>{row[\"processor_type\"]}</td>')\n        html_parts.append(f'<td>{row[\"activity_rate_pct\"]:.2f}%</td>')\n        html_parts.append(f'<td>{int(row[\"total_tasks\"]):,}</td>')\n        html_parts.append('</tr>')\n    html_parts.append('</table>')\n    if len(review_list) > 20:\n        html_parts.append(f'<p><em>Showing top 20 of {len(review_list)} processors requiring review.</em></p>')\nelse:\n    html_parts.append('<p>‚úì No processors require review!</p>')\n\n# Active processors summary\nkeep_list = processor_metrics[processor_metrics['recommendation'] == 'Keep']\nhtml_parts.append(f'<h3>Active Processors ({len(keep_list)} processors)</h3>')\nhtml_parts.append(f'<p>‚úì {len(keep_list)} processors are active and should be kept.</p>')\nhtml_parts.append(f'<p>Average activity rate: {keep_list[\"activity_rate_pct\"].mean():.1f}%</p>')\nhtml_parts.append(f'<p>Total throughput (30d): {int(keep_list[\"total_flowfiles_out\"].sum()):,} flowfiles</p>')\n\nprint(\"‚úì Cleanup recommendations section created\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Close HTML and Add JavaScript\n",
    "\n",
    "html_parts.append(\"\"\"\n",
    "    <script>\n",
    "        function toggleFlow(id) {\n",
    "            var content = document.getElementById('content-' + id);\n",
    "            var toggle = document.getElementById('toggle-' + id);\n",
    "            if (content.style.display === 'none') {\n",
    "                content.style.display = 'block';\n",
    "                toggle.textContent = '‚ñº';\n",
    "            } else {\n",
    "                content.style.display = 'none';\n",
    "                toggle.textContent = '‚ñ∂';\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\")\n",
    "\n",
    "# Combine all HTML parts\n",
    "html_content = ''.join(html_parts)\n",
    "\n",
    "print(\"‚úì HTML dashboard assembled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Export HTML and Summary Files\n",
    "\n",
    "print(\"Exporting files...\")\n",
    "\n",
    "# Write HTML dashboard\n",
    "with open(CONFIG['output_file'], 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "print(f\"‚úì HTML dashboard saved to: {CONFIG['output_file']}\")\n",
    "\n",
    "# Export summary JSON\n",
    "summary_file = CONFIG['output_dir'] + 'summary_stats.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "print(f\"‚úì Summary stats saved to: {summary_file}\")\n",
    "\n",
    "# Export cleanup CSV\n",
    "cleanup_file = CONFIG['output_dir'] + 'cleanup_recommendations_all_flows.csv'\n",
    "cleanup_cols = ['server', 'flow_name', 'processor_id', 'processor_name', 'processor_type',\n",
    "                'recommendation', 'activity_rate_pct', 'days_since_active', 'last_run_status']\n",
    "processor_metrics[cleanup_cols].to_csv(cleanup_file, index=False)\n",
    "print(f\"‚úì Cleanup recommendations saved to: {cleanup_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ DASHBOARD GENERATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMain dashboard: {CONFIG['output_file']}\")\n",
    "print(f\"Summary stats: {summary_file}\")\n",
    "print(f\"Cleanup CSV: {cleanup_file}\")\n",
    "print(f\"\\nüìä Total processors: {summary['total_processors']}\")\n",
    "print(f\"üî¥ Cleanup candidates: {summary['cleanup_candidates']}\")\n",
    "print(f\"‚ö†Ô∏è  Review required: {summary['review_required']}\")\n",
    "print(f\"üü¢ Active: {len(keep_list)}\")\n",
    "print(f\"\\nOpen the HTML file in your browser to view the interactive dashboard!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}